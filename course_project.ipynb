{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Импорт нужных библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Данные об отклике абонентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть существенный дисбаланс классов, поэтому необходимо будет делать балансировку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также сразу подгрузим тестовые данные, для которых необходимо получить предсказание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на варианты предлагаемых услуг. Как видим ниже, всего абонентам предлагалась одна из 8 услуг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vas_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько услуг предлагалось одному абоненту. Как видим ниже, каждому абоненту предлагалось от 1 до 3 услуг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['id'])['vas_id'].count().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, предлагались ли какие-то услуги абоненту одновременно или между ними значительный временной интервал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['id', 'buy_time'])['vas_id'].count().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть крайне редко предлагалось более одной услуги в один момент времени (около 0,01% случаев)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но еще возможна ситуация, когда разница между временем предложений совсем небольшая (допустим, не более одного дня). То есть это по сути одновременно предлагаемые услуги, хотя buy_time у них не совпадает. Поищем и такие случаи.\n",
    "Один день - это 86400 секунд. То есть разница между двумя временными метками должна быть не больше чем 86400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого пользователя найдем три времени сделанных предложений: max, median и min. Поскольку предложений было не более трех, то среди значений max, median и min может быть от 1 до 3 различных значений.\n",
    "Если пользователю были сделаны предложения с интервалом не больше чем 86400, то одна из разностей значений (max - median) или (median - min) должна быть не больше чем 86400 (но больше нуля).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_stats = (pd.DataFrame(data.groupby(['id'])['buy_time'].max() - data.groupby(['id'])['buy_time'].median())).rename(columns={'buy_time':'buy_time_diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_stats.loc[(buy_stats['buy_time_diff'] <= 86400)& (buy_stats['buy_time_diff'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_stats = (pd.DataFrame(data.groupby(['id'])['buy_time'].median() - data.groupby(['id'])['buy_time'].min())).rename(columns={'buy_time':'buy_time_diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_stats.loc[(buy_stats['buy_time_diff'] <= 86400)& (buy_stats['buy_time_diff'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, не было ни одного случая, когда абоненту предлагали несколько услуг с разницей менее суток. И, как было показано ранее, ничтожно мало случаев, когда несколько услуг предлагаются одновременно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примем это за политику компании и будем придерживаться ее и дальше при решении задачи: абонентам не будем предлагать несколько услуг одновременно или с небольшой разницей (до суток)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, были ли случаи, когда одному абоненту предлагали одни и те же услуги несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['id', 'vas_id'])['vas_id'].count().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в примерно 0.75% случаев одна и та же услуга предлагалась абоненту дважды. То есть, по-видимому, это допускается политикой компании в особых случаях. В таком случае, оценивая, какие услуги предложить абоненту, мы сможем предлагать и ранее предложенные услуги (в исключительных случаях, при хорошей вероятности положительного отклика)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОДЫ.\n",
    "Для дальнейшего будем считать, что: \n",
    "1. Предлагать пользователю можно только одну услугу, даже в случае хороших прогнозов по нескольким услугам.\n",
    "2. Даже если пользователь ранее уже отказался от услуги, то все равно ему можно попробовать предложить эту услугу в дальнейшем при условии очень хороших прогнозов по отклику.\n",
    "\n",
    "Мы не будем использовать эти выводы в процессе предобработки данных и при обучении моделей, но они пригодятся для формирования итоговых предложений пользователям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Профили пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dd.read_csv('features.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, много ли пользователей имеет несколько профилей на разные временные метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "features.groupby('id').buy_time.count().value_counts().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, около 3% пользователей имеет по два профиля, а остальные - один профиль. Поскольку процент пользователей с двумя профилями достаточно большой, то при соединении датафрейма откликов с датафреймом профилей пользователей для каждого отклика необходимо будет находить ближайший по времени профиль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Соединение таблиц профилей и откликов"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Далее нам нужно к датафрейму откликов присоединить признаки из датафрейма пользователей. Будем использовать следующий принцип соединения: для каждого отклика выбирается тот профиль пользователя, где временная метка ближайшая к метке отклика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку таблица features очень большая и может не поместиться в оперативной памяти, то сначала отфильтруем ее, оставив только те профили, пользователи которых присутствуют в таблице data или data_test. Это уже будет сравнительно небольшая таблица, с которой можно работать без dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cut = features.loc[features['id'].isin(list(data['id'])+list(data_test['id']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соединим таблицу features_cut с data и data_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "merged_data = pd.merge_asof(data.sort_values('buy_time'), features_cut.compute().sort_values('buy_time'), on='buy_time', by='id', direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "merged_data_test = pd.merge_asof(data_test.sort_values('buy_time'), features_cut.compute().sort_values('buy_time'), on='buy_time', by='id', direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del data_test\n",
    "del features_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь таблицы готовы для решения задачи. Сохраним их в pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_pickle(\"merged_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_test.to_pickle(\"merged_data_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"merged_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target(df, target_name, method='over'):\n",
    "\n",
    "    assert method in ['over', 'under', 'tomek', 'smote'], 'Неверный метод сэмплирования'\n",
    "    \n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.argmax()\n",
    "    minor_class_name = target_counts.argmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "    if method == 'over':\n",
    "        for i in range(disbalance_coeff):\n",
    "            sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "            df = df.append(sample, ignore_index=True)\n",
    "            \n",
    "    elif method == 'under':\n",
    "        df_ = df.copy()\n",
    "        df = df_[df_[target_name] == minor_class_name]\n",
    "        tmp = df_[df_[target_name] == major_class_name]\n",
    "        df = df.append(tmp.iloc[\n",
    "            np.random.randint(0, tmp.shape[0], target_counts[minor_class_name])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    elif method == 'tomek':\n",
    "        from imblearn.under_sampling import TomekLinks\n",
    "        tl = TomekLinks()\n",
    "        X_tomek, y_tomek = tl.fit_sample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_tomek, y_tomek], axis=1)\n",
    "    \n",
    "    elif method == 'smote':\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE()\n",
    "        X_smote, y_smote = smote.fit_sample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_smote, y_smote], axis=1)\n",
    "\n",
    "    return df.sample(frac=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = balance_df_by_target(data, 'target', method='under')\n",
    "    \n",
    "data_balanced['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Проверка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наличие пропусков в данных. Как увидим ниже, пропуски отсутствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Dummy-переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_balanced.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки числовые. Преобразуем признак vas_id в тип object, так как это по сути категориальный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced['vas_id'] = data_balanced.astype({'vas_id': 'object'})['vas_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем признак vas_id (только он является нечисловым)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(data_balanced, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Стандартизация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данных удалим атрибуты 'Unnamed: 0_x', 'id', 'Unnamed: 0_y', не несущие значимой информации. Качество моделей будем оценивать с помощью кросс-валидации, поэтому не требуется разбиение данных на train и test (valid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dum.drop(columns=['Unnamed: 0_x', 'id', 'Unnamed: 0_y', 'target'])\n",
    "y = data_dum['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Генерация новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство признаков мы никак не можем интерпретировать, поскольку данные обезличены. Но можем попробовать что-то сделать с признаком buy_time (время покупки). \n",
    "Сейчас этот признак представлен в формате timestamp, и он может быть полезен прямо в таком виде, как числовой признак (поскольку с течением времени вполне могут наблюдаться определенные тенденции действий покупателей - подключение услуги или отказ от нее, то корректно сравнивать этот признак на больше-меньше). \n",
    "Дополнительно мы также можем сгенерировать из этого признака новые признаки, такие как день недели, месяц, час дня. Вполне возможно, что в действиях покупателей наблюдается определенная цикличность: например, ночью покупатели менее лояльны и чаще отказываются от услуги, чем подключают ее. Или, допустим, люди со стандартным графиком работы 5/2 реже подключают услуги по понедельникам (потому что \"понедельник - день тяжелый\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможные дни недели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(datetime.fromtimestamp(x).timetuple().tm_wday for x in data_balanced['buy_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть каждый раз новая услуга предлагалась в понедельник. Значит, нет смысла в таком признаке для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможные часы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(datetime.fromtimestamp(x).hour for x in data_balanced['buy_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть новая услуга всегда предлагалась в районе полуночи, и пользы от такого признака тоже нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможные месяцы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(datetime.fromtimestamp(x).month for x in data_balanced['buy_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в данных train использованы данные с июля по декабрь. Данный признак не будет нам полезен в ближайшей перспективе (для предсказания ответов с начала года)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, рассмотренные признаки не являются полезными, и мы не будем их генерировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Baseline-решение - логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовой модели будем использовать логистическую регрессию. Для оценки качества будет использоваться кросс-валидация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "c_values = np.logspace(-2, 3, 50)\n",
    "model_lr = LogisticRegressionCV(random_state=0, Cs=c_values, cv=skf, verbose=1, n_jobs=-1, scoring='f1_macro')\n",
    "model_lr.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = model_lr.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, pred_lr, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(pred_lr, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, базовое решение дало f1-score 0,671. Будем пробовать его улучшать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Другие алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее выполненная предобработка данных подойдет и для следующих алгоритмов, которые мы попробуем применить: решающие деревья и CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_features': np.arange(5, 10),\n",
    "    'max_depth': np.arange(5, 10),\n",
    "}\n",
    "            \n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid=parameters,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf = clf.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, pred_clf, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный результат хуже результата базового решения, на основе логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catb = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'depth' : [4,5,6,7,8,9,10],\n",
    "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "              'iterations' : [10, 20]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params = {\n",
    "     'silent':True,\n",
    "     'random_state':21,\n",
    "     'eval_metric':'F1',\n",
    "     'early_stopping_rounds':20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb = GridSearchCV(estimator=model_catb, param_grid = parameters, cv = 5, scoring='f1_macro')\n",
    "grid_model_catb.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_catb = grid_model_catb.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, pred_catb, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred_catb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, f1_score равен 0,888 - выше, чем в предыдущих моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Снижение размерности пространства признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сможем ли мы улучшить результат работы CatBoost, если предварительно выполним снижение размерности пространства признаков с помощью метода PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, сколько необходимо взять главных компонент. Для этого посмотрим на накапливаемую сумму параметра explained_variance_ratio_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_scaled)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметр n_components в PCA так, чтобы процент объясненной дисперсии был не менее чем 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "for i in range(len(cumsum_variance)):\n",
    "    if cumsum_variance[i] >=0.95:\n",
    "        break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, можно взять n_components равный 151."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=145)\n",
    "principalComponents_2 = pca.fit_transform(X_scaled)\n",
    "principal_data_2 = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "principal_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно пробовать вновь применять метод CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catb_2 = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'depth' : [4,5,6,7,8,9,10],\n",
    "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "              'iterations' : [10, 20]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params = {\n",
    "     'silent':True,\n",
    "     'random_state':21,\n",
    "     'eval_metric':'F1',\n",
    "     'early_stopping_rounds':20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb_2 = GridSearchCV(estimator=model_catb_2, param_grid = parameters, cv = 5, scoring='f1_macro')\n",
    "grid_model_catb_2.fit(principal_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_catb_2 = grid_model_catb_2.predict(principal_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, pred_catb_2, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred_catb_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, качество работы модели ухудшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем понизить размерность не настолько сильно. Ранее использовали параметр n_components равный 145, а теперь возьмем его равным 180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3 = PCA(n_components=180)\n",
    "principalComponents_3 = pca.fit_transform(X_scaled)\n",
    "principal_data_3 = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "principal_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catb_3 = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'depth' : [4,5,6,7,8,9,10],\n",
    "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "              'iterations' : [10, 20]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params = {\n",
    "     'silent':True,\n",
    "     'random_state':21,\n",
    "     'eval_metric':'F1',\n",
    "     'early_stopping_rounds':20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb_3 = GridSearchCV(estimator=model_catb_3, param_grid = parameters, cv = 5, scoring='f1_macro')\n",
    "grid_model_catb_3.fit(principal_data_3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_catb_3 = grid_model_catb_3.predict(principal_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, pred_catb_3, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_catb_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred_catb_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1_score вырос, но незначительно (с 0.821 до 0.824). По-видимому, при понижении размерности мы теряем довольно много информации, существенной для решения задачи классификации. Поэтому не будем применять этот метод в конечном решении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, для финального решения будем использовать CatBoost с параметрами grid_model_catb.best_params_ ('depth': 4, 'iterations': 10, 'learning_rate': 0.03)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Прогнозирование на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = grid_model_catb.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_proba = grid_model_catb.predict_proba(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data_test\".csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Создание и сохранение пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый пайплайн должен выполнять следующие последовательные действия:\n",
    "   1. Готовить исходные данные: \n",
    "      - соединять таблицы откликов и профилей;\n",
    "      - создавать dummy-переменные;\n",
    "      - выполнять стандартизацию данных;\n",
    "   2. Выполнять классификацию с помощью обученной модели CatBoost.\n",
    "\n",
    "При обучении модели будем подавать на вход таблицу, в которой уже произведена балансировка классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1. Создание пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформер для соединения таблиц откликов и профилей\n",
    "class JoinTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.features = dd.read_csv('features.csv', sep='\\t')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        features_cut = self.features.loc[self.features['id'].isin(X['id'])]\n",
    "        merged_data = pd.merge_asof(X.sort_values('buy_time'), features_cut.compute().sort_values('buy_time'), on='buy_time', by='id', direction='nearest')\n",
    "        return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key, drop_first=True)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['vas_id']\n",
    "numerical_columns = list(data.columns)\n",
    "numerical_columns.remove('Unnamed: 0_x')\n",
    "numerical_columns.remove('id')\n",
    "numerical_columns.remove('Unnamed: 0_y')\n",
    "numerical_columns.remove('target')\n",
    "numerical_columns.remove('vas_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем отдельно два пайплайна: один для соединения таблиц data и features, другой для предобработки данных и обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_merge = Pipeline([('join', JoinTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = []\n",
    "\n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', FeatureSelector(column=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for num_col in numerical_columns:\n",
    "    num_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=num_col)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((num_col, num_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_catboost = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', CatBoostClassifier(depth=4, iterations=10, learning_rate=0.03, silent=True, random_state=21,\n",
    "                                eval_metric='F1', early_stopping_rounds=20)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diman\\AppData\\Local\\Temp\\ipykernel_3080\\2281545907.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp.iloc[\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    60186\n",
       "1.0    60186\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_balanced = balance_df_by_target(data, 'target', method='under')\n",
    "    \n",
    "data_train_balanced['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train_balanced.drop(columns=['target'])\n",
    "y_train = data_train_balanced['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('join', JoinTransformer())])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_merge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = pipeline_merge.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('vas_id',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='vas_id')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='vas_id'))])),\n",
       "                                                ('buy_time',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='buy_time')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('0',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='0')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScal...\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='25')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('26',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='26')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('27',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='27')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])), ...])),\n",
       "                ('classifier',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x000000CC47090AC0>)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. Предсказание отклика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_merged = pipeline_merge.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31640558, 0.31640558, 0.64402677, 0.64402677, 0.64402677,\n",
       "       0.64402677, 0.64402677, 0.31640558, 0.31640558, 0.59706428])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline_catboost.predict_proba(data_test_merged)[:, 1]\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv('answers_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4. Сохранение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pipeline_merge.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline_merge, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pipeline_catboost.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline_catboost, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Применение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем загрузить и применить модели для предсказания отклика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline_merge.pkl', 'rb') as f:\n",
    "        pipeline_merge_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline_catboost.pkl', 'rb') as f:\n",
    "        pipeline_catboost_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_test = pipeline_merge_test.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline_catboost_test.predict_proba(data_test_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3130519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1099444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>0.644027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1343255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547413200</td>\n",
       "      <td>0.644027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1277040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>0.644027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  vas_id    buy_time    target\n",
       "0           0  3130519     2.0  1548018000  0.316406\n",
       "1           1  2000860     4.0  1548018000  0.316406\n",
       "2           2  1099444     2.0  1546808400  0.644027\n",
       "3           3  1343255     5.0  1547413200  0.644027\n",
       "4           4  1277040     2.0  1546808400  0.644027"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv('answers_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
